#!/usr/bin/env python3
"""
éªŒè¯Chileanæ•°æ®é›†ç‚¹äº‘æ–‡ä»¶è¯»å–æ˜¯å¦æ­£ç¡®
"""

import os
import sys
import numpy as np
import pickle
import random
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = "/home/wzj/pan1/MinkLoc3Dv2"
if project_path not in sys.path:
    sys.path.append(project_path)

# å¯¼å…¥Chileanç‚¹äº‘åŠ è½½å™¨
try:
    from datasets.chilean.chilean_raw import ChileanPointCloudLoader

    print("âœ… æˆåŠŸå¯¼å…¥ChileanPointCloudLoader")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ChileanPointCloudLoaderå¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²æ­£ç¡®åˆ›å»º datasets/chilean/chilean_raw.py æ–‡ä»¶")
    sys.exit(1)


def test_direct_file_loading():
    """ç›´æ¥æµ‹è¯•ç‚¹äº‘æ–‡ä»¶åŠ è½½"""
    print("ğŸ” æµ‹è¯•ç›´æ¥ç‚¹äº‘æ–‡ä»¶åŠ è½½...")

    dataset_path = "/home/wzj/pan2/Chilean_Underground_Mine_Dataset_Many_Times"

    # æ‰¾ä¸€äº›ç¤ºä¾‹æ–‡ä»¶
    sample_files = []
    for series in [10, 11, 12]:
        series_dir = os.path.join(dataset_path, f"downsampled_simdata_{series}")
        if os.path.exists(series_dir):
            for subdir in os.listdir(series_dir):
                subdir_path = os.path.join(series_dir, subdir)
                if os.path.isdir(subdir_path) and subdir.startswith("downsampled_simdata_"):
                    # æ‰¾ç¬¬ä¸€ä¸ªtxtæ–‡ä»¶
                    for file in os.listdir(subdir_path):
                        if file.endswith('.txt'):
                            sample_files.append(os.path.join(subdir_path, file))
                            break
                if len(sample_files) >= 3:
                    break
        if len(sample_files) >= 3:
            break

    if not sample_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç‚¹äº‘æ–‡ä»¶")
        return False

    print(f"æ‰¾åˆ° {len(sample_files)} ä¸ªç¤ºä¾‹æ–‡ä»¶")

    loader = ChileanPointCloudLoader()

    for i, file_path in enumerate(sample_files):
        print(f"\nğŸ“„ æµ‹è¯•æ–‡ä»¶ {i + 1}: {os.path.basename(file_path)}")
        print(f"   å®Œæ•´è·¯å¾„: {file_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            continue

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path) / 1024  # KB
        print(f"   ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f} KB")

        # è¯»å–å‰å‡ è¡ŒæŸ¥çœ‹æ ¼å¼
        try:
            with open(file_path, 'r') as f:
                lines = f.readlines()[:5]
            print(f"   ğŸ“ å‰5è¡Œå†…å®¹:")
            for j, line in enumerate(lines):
                print(f"      è¡Œ{j + 1}: {line.strip()}")
        except Exception as e:
            print(f"   âŒ è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            continue

        # ä½¿ç”¨åŠ è½½å™¨è¯»å–
        try:
            pc = loader(file_path)
            print(f"   âœ… åŠ è½½å™¨è¯»å–æˆåŠŸ")
            print(f"   ğŸ“Š ç‚¹äº‘ä¿¡æ¯:")
            print(f"      å½¢çŠ¶: {pc.shape}")
            print(f"      æ•°æ®ç±»å‹: {pc.dtype}")

            if len(pc) > 0:
                print(f"      XèŒƒå›´: {pc[:, 0].min():.3f} åˆ° {pc[:, 0].max():.3f}")
                print(f"      YèŒƒå›´: {pc[:, 1].min():.3f} åˆ° {pc[:, 1].max():.3f}")
                print(f"      ZèŒƒå›´: {pc[:, 2].min():.3f} åˆ° {pc[:, 2].max():.3f}")

                # æ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆå€¼
                has_nan = np.any(np.isnan(pc))
                has_inf = np.any(np.isinf(pc))
                print(f"      åŒ…å«NaN: {has_nan}")
                print(f"      åŒ…å«Inf: {has_inf}")

                # æ˜¾ç¤ºä¸€äº›æ ·æœ¬ç‚¹
                print(f"      å‰3ä¸ªç‚¹:")
                for k in range(min(3, len(pc))):
                    print(f"        ç‚¹{k + 1}: ({pc[k, 0]:.3f}, {pc[k, 1]:.3f}, {pc[k, 2]:.3f})")
            else:
                print(f"      âŒ ç©ºç‚¹äº‘")

        except Exception as e:
            print(f"   âŒ åŠ è½½å™¨è¯»å–å¤±è´¥: {e}")

    return True


def test_pickle_file_loading():
    """æµ‹è¯•ä»pickleæ–‡ä»¶ä¸­åŠ è½½ç‚¹äº‘"""
    print("\nğŸ” æµ‹è¯•ä»pickleæ–‡ä»¶åŠ è½½ç‚¹äº‘...")

    dataset_path = "/home/wzj/pan2/Chilean_Underground_Mine_Dataset_Many_Times"
    pickle_file = os.path.join(dataset_path, "training_queries_baseline_chilean.pickle")

    if not os.path.exists(pickle_file):
        print(f"âŒ Pickleæ–‡ä»¶ä¸å­˜åœ¨: {pickle_file}")
        return False

    try:
        with open(pickle_file, 'rb') as f:
            queries = pickle.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½pickleæ–‡ä»¶ï¼ŒåŒ…å« {len(queries)} ä¸ªæŸ¥è¯¢")
    except Exception as e:
        print(f"âŒ åŠ è½½pickleæ–‡ä»¶å¤±è´¥: {e}")
        return False

    # éšæœºé€‰æ‹©å‡ ä¸ªæŸ¥è¯¢è¿›è¡Œæµ‹è¯•
    sample_keys = random.sample(list(queries.keys()), min(3, len(queries)))
    loader = ChileanPointCloudLoader()

    for i, key in enumerate(sample_keys):
        query = queries[key]
        print(f"\nğŸ“‹ æµ‹è¯•æŸ¥è¯¢ {i + 1} (ID: {key}):")
        print(f"   æ–‡ä»¶è·¯å¾„: {query.rel_scan_filepath}")

        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.join(dataset_path, query.rel_scan_filepath)
        print(f"   å®Œæ•´è·¯å¾„: {full_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(full_path):
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            continue

        # ä½¿ç”¨åŠ è½½å™¨è¯»å–
        try:
            pc = loader(full_path)
            print(f"   âœ… æˆåŠŸè¯»å–ç‚¹äº‘")
            print(f"   ğŸ“Š ç‚¹äº‘ä¿¡æ¯:")
            print(f"      å½¢çŠ¶: {pc.shape}")
            print(f"      æŸ¥è¯¢ä½ç½®: ({query.position[0]:.3f}, {query.position[1]:.3f})")
            print(f"      æ­£æ ·æœ¬æ•°é‡: {len(query.positives)}")
            print(f"      éè´Ÿæ ·æœ¬æ•°é‡: {len(query.non_negatives)}")

            if len(pc) > 0:
                print(f"      ç‚¹äº‘ä¸­å¿ƒ: ({pc[:, 0].mean():.3f}, {pc[:, 1].mean():.3f}, {pc[:, 2].mean():.3f})")
        except Exception as e:
            print(f"   âŒ è¯»å–ç‚¹äº‘å¤±è´¥: {e}")

    return True


def visualize_sample_pointcloud():
    """å¯è§†åŒ–ç¤ºä¾‹ç‚¹äº‘"""
    print("\nğŸ¨ å¯è§†åŒ–ç¤ºä¾‹ç‚¹äº‘...")

    dataset_path = "/home/wzj/pan2/Chilean_Underground_Mine_Dataset_Many_Times"
    pickle_file = os.path.join(dataset_path, "training_queries_baseline_chilean.pickle")

    if not os.path.exists(pickle_file):
        print(f"âŒ Pickleæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯è§†åŒ–")
        return False

    try:
        with open(pickle_file, 'rb') as f:
            queries = pickle.load(f)

        # é€‰æ‹©ç¬¬ä¸€ä¸ªæŸ¥è¯¢
        first_key = list(queries.keys())[0]
        query = queries[first_key]

        loader = ChileanPointCloudLoader()
        full_path = os.path.join(dataset_path, query.rel_scan_filepath)

        if not os.path.exists(full_path):
            print(f"âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            return False

        pc = loader(full_path)

        if len(pc) == 0:
            print(f"âŒ ç©ºç‚¹äº‘ï¼Œæ— æ³•å¯è§†åŒ–")
            return False

        print(f"âœ… å‡†å¤‡å¯è§†åŒ–ç‚¹äº‘: {query.rel_scan_filepath}")
        print(f"   ç‚¹æ•°: {len(pc)}")

        # åˆ›å»º3Då›¾
        fig = plt.figure(figsize=(12, 8))
        ax = fig.add_subplot(111, projection='3d')

        # ä¸ºäº†æ€§èƒ½ï¼Œå¦‚æœç‚¹å¤ªå¤šå°±é‡‡æ ·
        if len(pc) > 5000:
            indices = np.random.choice(len(pc), 5000, replace=False)
            pc_vis = pc[indices]
            print(f"   é‡‡æ ·åˆ° {len(pc_vis)} ä¸ªç‚¹è¿›è¡Œå¯è§†åŒ–")
        else:
            pc_vis = pc

        # ç»˜åˆ¶ç‚¹äº‘
        scatter = ax.scatter(pc_vis[:, 0], pc_vis[:, 1], pc_vis[:, 2],
                             c=pc_vis[:, 2], cmap='viridis', s=1, alpha=0.6)

        ax.set_xlabel('X (m)')
        ax.set_ylabel('Y (m)')
        ax.set_zlabel('Z (m)')
        ax.set_title(f'Chilean pointcloud : {os.path.basename(query.rel_scan_filepath)}')

        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(scatter, ax=ax, label='Z (m)')

        # è®¾ç½®ç­‰æ¯”ä¾‹
        # ax.set_box_aspect([1,1,1])

        # ä¿å­˜å›¾ç‰‡
        output_path = os.path.join(os.path.dirname(__file__), 'chilean_pointcloud_sample.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"   ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {output_path}")

        # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¦‚æœåœ¨æ¡Œé¢ç¯å¢ƒä¸­ï¼‰
        try:
            plt.show()
        except:
            print("   â„¹ï¸ æ— æ³•æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¯èƒ½ä¸åœ¨æ¡Œé¢ç¯å¢ƒä¸­ï¼‰")

        return True

    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        return False


def compare_with_oxford_format():
    """ä¸Oxfordæ•°æ®é›†æ ¼å¼å¯¹æ¯”"""
    print("\nğŸ” ä¸Oxfordæ•°æ®é›†æ ¼å¼å¯¹æ¯”...")

    # æ¨¡æ‹Ÿè¯»å–ä¸€ä¸ªOxford .binæ–‡ä»¶çš„è¿‡ç¨‹
    print("Oxfordæ•°æ®é›†ç‰¹ç‚¹:")
    print("  - æ–‡ä»¶æ ¼å¼: .bin (äºŒè¿›åˆ¶)")
    print("  - åæ ‡ç³»ç»Ÿ: ç»çº¬åº¦ (northing, easting)")
    print("  - æ•°æ®ç»„ç»‡: é¢„å¤„ç†çš„ç‚¹äº‘ï¼Œå·²ç§»é™¤åœ°é¢")
    print("  - ç‚¹æ•°: å›ºå®šæ•°é‡")

    print("\nChileanæ•°æ®é›†ç‰¹ç‚¹:")
    print("  - æ–‡ä»¶æ ¼å¼: .txt (æ–‡æœ¬)")
    print("  - åæ ‡ç³»ç»Ÿ: 3Dåæ ‡ (x, y, z)")
    print("  - æ•°æ®ç»„ç»‡: åŸå§‹ç‚¹äº‘ + intensity")
    print("  - ç‚¹æ•°: å¯å˜æ•°é‡")

    # æµ‹è¯•Chileanç‚¹äº‘
    dataset_path = "/home/wzj/pan2/Chilean_Underground_Mine_Dataset_Many_Times"
    loader = ChileanPointCloudLoader()

    # åˆ†æå‡ ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
    sample_files = []
    for series in [10, 11]:
        series_dir = os.path.join(dataset_path, f"downsampled_simdata_{series}")
        if os.path.exists(series_dir):
            for subdir in os.listdir(series_dir):
                subdir_path = os.path.join(series_dir, subdir)
                if os.path.isdir(subdir_path):
                    txt_files = [f for f in os.listdir(subdir_path) if f.endswith('.txt')]
                    if txt_files:
                        sample_files.extend([os.path.join(subdir_path, f) for f in txt_files[:2]])
                if len(sample_files) >= 5:
                    break
        if len(sample_files) >= 5:
            break

    if sample_files:
        point_counts = []
        spatial_ranges = []

        for file_path in sample_files[:5]:
            try:
                pc = loader(file_path)
                if len(pc) > 0:
                    point_counts.append(len(pc))
                    x_range = pc[:, 0].max() - pc[:, 0].min()
                    y_range = pc[:, 1].max() - pc[:, 1].min()
                    z_range = pc[:, 2].max() - pc[:, 2].min()
                    spatial_ranges.append((x_range, y_range, z_range))
            except:
                continue

        if point_counts:
            print(f"\nChileanæ•°æ®é›†ç»Ÿè®¡ (åŸºäº{len(point_counts)}ä¸ªæ ·æœ¬):")
            print(f"  å¹³å‡ç‚¹æ•°: {np.mean(point_counts):.0f}")
            print(f"  ç‚¹æ•°èŒƒå›´: {min(point_counts)} - {max(point_counts)}")

            if spatial_ranges:
                avg_x_range = np.mean([r[0] for r in spatial_ranges])
                avg_y_range = np.mean([r[1] for r in spatial_ranges])
                avg_z_range = np.mean([r[2] for r in spatial_ranges])
                print(f"  å¹³å‡ç©ºé—´èŒƒå›´:")
                print(f"    X: {avg_x_range:.2f}m")
                print(f"    Y: {avg_y_range:.2f}m")
                print(f"    Z: {avg_z_range:.2f}m")


def main():
    print("ğŸ” Chileanæ•°æ®é›†ç‚¹äº‘è¯»å–éªŒè¯")
    print("=" * 50)

    # æµ‹è¯•1: ç›´æ¥æ–‡ä»¶åŠ è½½
    success1 = test_direct_file_loading()

    # æµ‹è¯•2: ä»pickleæ–‡ä»¶åŠ è½½
    success2 = test_pickle_file_loading()

    # æµ‹è¯•3: å¯è§†åŒ–
    try:
        success3 = visualize_sample_pointcloud()
    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–è·³è¿‡: {e}")
        success3 = True  # å¯è§†åŒ–å¤±è´¥ä¸å½±å“æ•´ä½“éªŒè¯

    # æµ‹è¯•4: æ ¼å¼å¯¹æ¯”
    compare_with_oxford_format()

    print("\n" + "=" * 50)
    if success1 and success2:
        print("ğŸ‰ ç‚¹äº‘è¯»å–éªŒè¯é€šè¿‡!")
        print("âœ… Chileanæ•°æ®é›†ç‚¹äº‘æ–‡ä»¶è¯»å–æ­£ç¡®")
        print("ğŸ’¡ å»ºè®®:")
        print("  - ç‚¹äº‘æ ¼å¼ç¬¦åˆé¢„æœŸ")
        print("  - å¯ä»¥æ­£å¸¸è¿›è¡Œè®­ç»ƒ")
        return 0
    else:
        print("âŒ ç‚¹äº‘è¯»å–éªŒè¯å¤±è´¥!")
        print("ğŸ”§ å»ºè®®æ£€æŸ¥:")
        print("  - æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("  - ç‚¹äº‘æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("  - ChileanPointCloudLoaderæ˜¯å¦æ­£ç¡®å®ç°")
        return 1


if __name__ == "__main__":
    sys.exit(main())